{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf0362f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_16132\\2389691454.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mf1_score\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapplications\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minception_v3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mInceptionV3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpreprocess_input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0moptimizers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \"\"\"\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdistribute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minput_layer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mInput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msequential\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\models\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunctional\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mFunctional\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msequential\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtraining\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\functional.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtensor\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mlayout_map\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mlayout_map_lib\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbase_layer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbase_layer_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\dtensor\\layout_map.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtensor\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mlazy_variable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtensor\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mutils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbase_layer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;31m# isort: off\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmixed_precision\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mloss_scale_optimizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmixed_precision\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpolicy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaved_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mlayer_serialization\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mgeneric_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mlayer_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaved_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbase_serialization\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaved_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mconstants\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaved_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msave_impl\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaved_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mserialized_attributes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mgeneric_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\saving\\saved_model\\save_impl.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msaving_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaved_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mconstants\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaved_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mload\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mkeras_load\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaved_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mserialized_attributes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaved_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mutils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\saving\\saved_model\\load.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0minput_spec\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer_v2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0moptimizer_v2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 29\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprotobuf\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msaved_metadata_pb2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     30\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprotobuf\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mversions_pb2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msaving_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\protobuf\\saved_metadata_pb2.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprotobuf\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mversions_pb2\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mkeras_dot_protobuf_dot_versions__pb2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\protobuf\\versions_pb2.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     34\u001B[0m   \u001B[0mcontaining_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m   fields=[\n\u001B[1;32m---> 36\u001B[1;33m     _descriptor.FieldDescriptor(\n\u001B[0m\u001B[0;32m     37\u001B[0m       \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'producer'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfull_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'third_party.py.keras.protobuf.VersionDef.producer'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m       \u001B[0mnumber\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcpp_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\google\\protobuf\\descriptor.py\u001B[0m in \u001B[0;36m__new__\u001B[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001B[0m\n\u001B[0;32m    559\u001B[0m                 \u001B[0mhas_default_value\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontaining_oneof\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mjson_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    560\u001B[0m                 file=None, create_key=None):  # pylint: disable=redefined-builtin\n\u001B[1;32m--> 561\u001B[1;33m       \u001B[0m_message\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMessage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_CheckCalledFromGeneratedFile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    562\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mis_extension\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    563\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_message\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdefault_pool\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFindExtensionByName\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfull_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2    \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from IPython.core.display import display, HTML\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "plt.style.use('ggplot')\n",
    "from tensorflow.keras.utils import load_img\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce254e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b112d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables \n",
    "main_folder = '../DataSets/'\n",
    "images_folder = main_folder + 'Img_align_celeba/img_align_celeba/img_align_celeba/'\n",
    "\n",
    "EXAMPLE_PIC = images_folder + '000506.jpg'\n",
    "\n",
    "TRAINING_SAMPLES = 10000\n",
    "VALIDATION_SAMPLES = 2000\n",
    "TEST_SAMPLES = 2000\n",
    "IMG_WIDTH = 178\n",
    "IMG_HEIGHT = 218\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a897f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data set that include the attribute for each picture\n",
    "df_attr = pd.read_csv(main_folder + 'list_attr_celeba.csv')\n",
    "df_attr.set_index('image_id', inplace=True)\n",
    "df_attr.replace(to_replace=-1, value=0, inplace=True) #replace -1 by 0\n",
    "df_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc86828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of available attributes\n",
    "for i, j in enumerate(df_attr.columns):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot picture and attributes\n",
    "img = load_img(EXAMPLE_PIC)\n",
    "plt.grid(False)\n",
    "plt.imshow(img)\n",
    "df_attr.loc[EXAMPLE_PIC.split('/')[-1]][['Smiling','Male','Young']] #some attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85eece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female or Male?\n",
    "plt.title('Female or Male')\n",
    "sns.countplot(y='Male', data=df_attr, color=\"c\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252b7fa",
   "metadata": {},
   "source": [
    "### Step 2: Split Dataset into Training, Validation and Test\n",
    "\n",
    "The recommended partitioning of images into training, validation, testing of the data set is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f89a3f",
   "metadata": {},
   "source": [
    "- 1-162770 are training\n",
    "- 162771-182637 are validation\n",
    "- 182638-202599 are testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e3342",
   "metadata": {},
   "source": [
    "The partition is in file list_eval_partition.csv\n",
    "\n",
    "Due time execution, by now we will be using a reduced number of images:\n",
    "\n",
    "- Training 20000 images\n",
    "- Validation 5000 images\n",
    "- Test 5000 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ccecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomended partition\n",
    "df_partition = pd.read_csv(main_folder + '/img_align_celeba/list_eval_partition.csv')\n",
    "df_partition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display counter by partition\n",
    "# 0 -> TRAINING\n",
    "# 1 -> VALIDATION\n",
    "# 2 -> TEST\n",
    "df_partition['partition'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the partition with the attributes\n",
    "df_partition.set_index('image_id', inplace=True)\n",
    "df_par_attr = df_partition.join(df_attr['Male'], how='inner')\n",
    "df_par_attr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fefa4b0",
   "metadata": {},
   "source": [
    "### 2.1: Generate Partitions (Train, Validation, Test)\n",
    "Number of images need to be balanced in order to get a good performance for the model, each model will have its own folder of training, validation and test balanced data.\n",
    "\n",
    "This degree project explains how imbalanced training data impact on CNNs models:\n",
    "\n",
    "https://www.kth.se/social/files/588617ebf2765401cfcc478c/PHensmanDMasko_dkand15.pdf\n",
    "\n",
    "On this step we will create functions that will help us to create each partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reshape_img(fname):\n",
    "    img = load_img(fname)\n",
    "    x = img_to_array(img)/255.\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "\n",
    "    return x\n",
    "\n",
    "def generate_df(partition, attr, num_samples):\n",
    "    df_ = df_par_attr[(df_par_attr['partition'] == partition)\n",
    "                           & (df_par_attr[attr] == 0)].sample(int(num_samples/2))\n",
    "    df_ = pd.concat([df_,\n",
    "                      df_par_attr[(df_par_attr['partition'] == partition) \n",
    "                                  & (df_par_attr[attr] == 1)].sample(int(num_samples/2))])\n",
    "    # for Train and Validation\n",
    "    if partition != 2:\n",
    "        x_ = np.array([load_reshape_img(images_folder + fname) for fname in df_.index])\n",
    "        x_ = x_.reshape(x_.shape[0], 218, 178, 3)\n",
    "        y_ = np_utils.to_categorical(df_[attr],2)\n",
    "    # for Test\n",
    "    else:\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "        for index, target in df_.iterrows():\n",
    "            im = cv2.imread(images_folder + index)\n",
    "            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n",
    "            im = np.expand_dims(im, axis =0)\n",
    "            x_.append(im)\n",
    "            y_.append(target[attr])\n",
    "    return x_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a012b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate image generator for data augmentation\n",
    "datagen =  ImageDataGenerator(\n",
    "  #preprocessing_function=preprocess_input,\n",
    "  rotation_range=30,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True\n",
    ")\n",
    "# load one image and reshape\n",
    "img = load_img(EXAMPLE_PIC)\n",
    "x = img_to_array(img)/255.\n",
    "x = x.reshape((1,) + x.shape)\n",
    "# plot 10 augmented images of the loaded iamge\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.suptitle('Data Augmentation', fontsize=28)\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.grid(False)\n",
    "    plt.imshow( batch.reshape(218, 178, 3))\n",
    "    \n",
    "    if i == 9:\n",
    "        break\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "x_train, y_train = generate_df(0, 'Male', TRAINING_SAMPLES)\n",
    "# Train - Data Preparation - Data Augmentation with generators\n",
    "train_datagen =  ImageDataGenerator(\n",
    "  preprocessing_function=preprocess_input,\n",
    "  rotation_range=30,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    ")\n",
    "train_datagen.fit(x_train)\n",
    "train_generator = train_datagen.flow(\n",
    "x_train, y_train,\n",
    "batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data\n",
    "x_valid, y_valid = generate_df(1, 'Male', VALIDATION_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adce7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as p\n",
    "\n",
    "# Import InceptionV3 Model\n",
    "inc_model = InceptionV3(weights='DataSets/img_align_celeba/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                        include_top=False,\n",
    "                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "score = inc_model.history['val_binary_accuracy'].pop()\n",
    "\n",
    "inc_model.save('Models/inc_model.h5')\n",
    "\n",
    "\n",
    "print(\"number of layers:\", len(inc_model.layers))\n",
    "#inc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eec2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers\n",
    "x = inc_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2309bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the final model \n",
    "model_ = Model(inputs=inc_model.input, outputs=predictions)\n",
    "\n",
    "# Lock initial layers to do not be trained\n",
    "for layer in model_.layers[:52]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model\n",
    "model_.compile(optimizer=SGD(lr=0.0001, momentum=0.9)\n",
    "                    , loss='categorical_crossentropy'\n",
    "                    , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040454b5",
   "metadata": {},
   "source": [
    "number of layers: 311"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033025dc",
   "metadata": {},
   "source": [
    "### Inception-V3 model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7ea256",
   "metadata": {},
   "source": [
    "This is the structure of the Inception-V3 model, developed over the imagenet dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f17554",
   "metadata": {},
   "source": [
    "![convert notebook to web app](https://i.imgur.com/kdXUzu1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd17e2f",
   "metadata": {},
   "source": [
    "source: https://hackathonprojects.files.wordpress.com/2016/09/74911-image03.png\n",
    "\n",
    "The top layers (including classification) are not included. These layers will be replaced for the following layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ba9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers\n",
    "x = inc_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a22007a",
   "metadata": {},
   "source": [
    "#### New Top layers\n",
    "Layers to be trained with the new model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60619472",
   "metadata": {},
   "source": [
    "![convert notebook to web app](https://i.imgur.com/rWF7bRY.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the final model \n",
    "model_ = Model(inputs=inc_model.input, outputs=predictions)\n",
    "\n",
    "# Lock initial layers to do not be trained\n",
    "for layer in model_.layers[:52]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model\n",
    "model_.compile(optimizer=SGD(lr=0.0001, momentum=0.9)\n",
    "                    , loss='categorical_crossentropy'\n",
    "                    , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd231de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/models/sequential/ fit generator\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.inc.male.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_.fit_generator(train_generator\n",
    "                     , validation_data = (x_valid, y_valid)\n",
    "                      , steps_per_epoch= TRAINING_SAMPLES/BATCH_SIZE\n",
    "                      , epochs= NUM_EPOCHS\n",
    "                      , callbacks=[checkpointer]\n",
    "                      , verbose=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd19fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss function value through epochs\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(hist.history['loss'], label = 'train')\n",
    "plt.plot(hist.history['val_loss'], label = 'valid')\n",
    "plt.legend()\n",
    "plt.title('Loss Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy through epochs\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(hist.history['accuracy'], label = 'train')\n",
    "plt.plot(hist.history['val_accuracy'], label = 'valid')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701363b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the best model\n",
    "model_.load_weights('weights.best.inc.male.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "x_test, y_test = generate_df(2, 'Male', TEST_SAMPLES)\n",
    "\n",
    "# generate prediction\n",
    "model_predictions = [np.argmax(model_.predict(feature)) for feature in x_test ]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100 * np.sum(np.array(model_predictions)==y_test) / len(model_predictions)\n",
    "print('Model Evaluation')\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "print('f1_score:', f1_score(y_test, model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e503696",
   "metadata": {},
   "source": [
    "#### 5. Conclusion\n",
    "\n",
    "The built model using transfer learning from the InceptionV3 and adding custom layers successfully recognize the gender giving certain picture with 94.8% of accuracy over the test data. Nevertheless, there are some limitations detected and opportunities for improvements:\n",
    "\n",
    "- Train the algorithms with the entire data set of images. Due computational resource limitation, the model was train with a subset of images. Having an appropriate machine, the model can be trained including all the images. This will make the algorithm to learn from different context of the picture giving it more experience in order to predict better never seen images.\n",
    "\n",
    "- Use difference structures for the CNNs. This approach could give better performance to the model, is an expensive task anyway, as the model can be measure on the test data set after is trained, and this takes time and computational resources.\n",
    "\n",
    "- Watching the pictures of the CelebA Data Set, most of the pictures are almost a close-up to the face of the subject, this leads to the model to learn from this type of pictures, and in situation where the subjects is just a small portion of a picture, the model could not perform well. To deal with this, more sophisticated preprocessing data can be added or complement the data set with pictures that are not entirely based in close-up to the face of the subject.\n",
    "\n",
    "- Environments where there are more than one subject in the picture was not part of the scope of this Notebook, but it is a good improvement in order to develop a better application. OpenCV is a good candidate to help with this development, as it very accurate to detect feces and its position in the pictures, then that portion of the picture (the faces) can be classified separately using the developed models on this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e61b1a",
   "metadata": {},
   "source": [
    "#### 6. Let's play with the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdecc6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary to name the prediction\n",
    "gender_target = {0: 'Female'\n",
    "                , 1: 'Male'}\n",
    "\n",
    "def img_to_display(filename):\n",
    "    i = Image.open(filename)\n",
    "    i.thumbnail((200, 200), Image.LANCZOS)\n",
    "    \n",
    "    with BytesIO() as buffer:\n",
    "        i.save(buffer, 'jpeg')\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "def display_result(filename, prediction, target):\n",
    "    gender = 'Male'\n",
    "    gender_icon = \"https://i.imgur.com/nxWan2u.png\"\n",
    "        \n",
    "    if prediction[1] <= 0.5:\n",
    "        gender_icon = \"https://i.imgur.com/oAAb8rd.png\"\n",
    "        gender = 'Female'\n",
    "            \n",
    "    display_html = '''\n",
    "    <div style=\"overflow: auto;  border: 2px solid #D8D8D8;\n",
    "        padding: 5px; width: 420px;\" >\n",
    "        <img src=\"data:image/jpeg;base64,{}\" style=\"float: left;\" width=\"200\" height=\"200\">\n",
    "        <div style=\"padding: 10px 0px 0px 20px; overflow: auto;\">\n",
    "            <img src=\"{}\" style=\"float: left;\" width=\"40\" height=\"40\">\n",
    "            <h3 style=\"margin-left: 50px; margin-top: 2px;\">{}</h3>\n",
    "            <p style=\"margin-left: 50px; margin-top: -6px; font-size: 12px\">{} prob.</p>\n",
    "            <p style=\"margin-left: 50px; margin-top: -16px; font-size: 12px\">Real Target: {}</p>\n",
    "            <p style=\"margin-left: 50px; margin-top: -16px; font-size: 12px\">Filename: {}</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    '''.format(img_to_display(filename)\n",
    "               , gender_icon\n",
    "               , gender\n",
    "               , \"{0:.2f}%\".format(round(max(prediction)*100,2))\n",
    "               , gender_target[target]\n",
    "               , filename.split('/')[-1]\n",
    "               )\n",
    "\n",
    "    display(HTML(display_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d7195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_prediction(filename):\n",
    "    im = cv2.imread(filename)\n",
    "    im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (178, 218)).astype(np.float32) / 255.0\n",
    "    im = np.expand_dims(im, axis =0)\n",
    "    # prediction\n",
    "    result = model_.predict(im)\n",
    "    prediction = np.argmax(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9003f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select random images of the test partition\n",
    "df_to_test = df_par_attr[(df_par_attr['partition'] == 2)].sample(8)\n",
    "\n",
    "for index, target in df_to_test.iterrows():\n",
    "    result = gender_prediction(images_folder + index)\n",
    "    #display result\n",
    "    display_result(images_folder + index, result[0], target['Male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
