{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### ChatGpt_Tweets_Sentiment_Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentiment Analysis with Deep Learning using BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSets/EDA Sberbank Open Data/chatgpt_daily_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../DataSets/EDA Sberbank Open Data/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:18:28.494580300Z",
     "start_time": "2023-05-24T12:18:28.482561800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DataSets/EDA Sberbank Open Data/chatgpt_daily_tweets.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:18:29.652290Z",
     "start_time": "2023-05-24T12:18:29.423287100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                     tweet_id              tweet_created  \\\n5394   1.6441126481229005e+18  2023-04-06 22:59:36+00:00   \n21694     1649337047679930371  2023-04-21 08:59:30+00:00   \n8580   1.6447165609412076e+18  2023-04-08 14:59:20+00:00   \n5074   1.6440824590957322e+18  2023-04-06 20:59:38+00:00   \n23988     1649971278475063296  2023-04-23 02:59:42+00:00   \n13258  1.6463323282293391e+18  2023-04-13 01:59:49+00:00   \n22030     1649835413996019712  2023-04-22 17:59:49+00:00   \n9216   1.6449432076111094e+18  2023-04-09 05:59:56+00:00   \n17567     1647917682933764097  2023-04-17 10:59:27+00:00   \n9568    1.645124213617967e+18  2023-04-09 17:59:12+00:00   \n\n                  tweet_extracted  \\\n5394   2023-04-08 02:25:52.995103   \n21694  2023-04-23 21:54:55.928600   \n8580   2023-04-10 23:11:22.510407   \n5074   2023-04-08 02:25:50.670032   \n23988  2023-04-25 21:30:42.316316   \n13258  2023-04-15 22:21:44.924258   \n22030  2023-04-24 21:35:01.277494   \n9216   2023-04-11 22:54:23.343471   \n17567  2023-04-19 21:59:48.128929   \n9568   2023-04-11 22:54:37.481343   \n\n                                                    text lang  \\\n5394   .@Expedia is integrating #ChatGPT into its app...   en   \n21694  RT @itolife: 完全勝利しました！！（素振り）\\n本日22時から……ChatGPT...   ja   \n8580   RT @ThugStyle4ever: GPT-4無料で使えるやん\\nBingに実装されとる...   ja   \n5074   RT @stupefy_Malfoy: ใช่ๆ นี่เคยหาเปเป้อที่เป็น...   th   \n23988  このつぶやきが意味不明な人にはChatGPTは向いてない。\\nけれども結果的にはいつの間にか...   ja   \n13258  RT @gigazine: ゲームのNPCにChatGPTを仕込んだら勝手にパーティーの計画...   ja   \n22030  RT @DefenderEurop: 🔵 \"Cette jeune fille est ch...   fr   \n9216   ChatGPT recommended online casino JILIACE for ...   en   \n17567  RT @xo749100naniha: 一億総無思考社会へ。平気でウソをつくChatGPTを...   ja   \n9568   RT @FrKadel: My daughter, who's had a degree i...   en   \n\n                   user_id                       user_name   user_username  \\\n5394   1580579004460851200                       Kelsi Lee      LeeKelslee   \n21694             33908473        Francesc Puigdemont Sanz    francescsanz   \n8580            2281944000  京都室町さろん・Kyoto Muromachi Salon・  muromachisalon   \n5074            2357295380                               🌹     TiaraMagica   \n23988            108174833             牧野尚人makino takahito        tkmakino   \n13258            269778793                           中谷キョウ       nakayakyo   \n22030  1276859037905309698                Philippe Lagaune        PLagaune   \n9216   1623547784703139842                         JILIACE       jiliace88   \n17567            486573105                inKstall Educare        Inkstall   \n9568    886774963855736832                             陈桐晓    chentongxiao   \n\n                user_location  \\\n5394                      NaN   \n21694               Barcelona   \n8580                      NaN   \n5074              Gotham City   \n23988  Sapporo,Hokkaido,Japan   \n13258             ちーば君の口の上あたり   \n22030                     NaN   \n9216              philippines   \n17567                  Global   \n9568            United States   \n\n                                        user_description  \\\n5394   Tech Recruiter at Expedia Group!! Dreams about...   \n21694  InternetEntrepreneur, Growth&Marketing lover, ...   \n8580   💁🏻‍♀️心豊かに自己表現の自由な空間・Art de vivre・ 🏡 京町家 生谷家住宅 ...   \n5074   🐉 she/her 🧚‍♀️ intersectional feminist & multi...   \n23988  H2×O2水素発電車FCEV＝TOYOTA MIRAI2016年式で3度目の越冬&Schoo...   \n13258                          小説とか書きます。 マンガ、アニメ、ラノベに強い。   \n22030                                                NaN   \n9216    online casino philippines with free signup bonus   \n17567  Installing knowledge since 12 years.\\nLearning...   \n9568                                                 one   \n\n                    user_created  user_followers_count  user_following_count  \\\n5394   2022-10-13 15:19:43+00:00                  18.0                 376.0   \n21694  2009-04-21 13:50:19+00:00                 890.0                 933.0   \n8580   2014-01-08 10:27:57+00:00                  38.0                 191.0   \n5074   2014-02-23 02:33:24+00:00                 422.0                1228.0   \n23988  2010-01-25 02:59:59+00:00                 255.0                 190.0   \n13258  2011-03-21 12:45:57+00:00                1500.0                1534.0   \n22030  2020-06-27 12:45:23+00:00                1321.0                3331.0   \n9216   2023-02-09 05:02:23+00:00                   0.0                   4.0   \n17567  2012-02-08 12:47:39+00:00                 212.0                   4.0   \n9568   2017-07-17 02:30:01+00:00                  23.0                 447.0   \n\n       user_tweet_count user_verified  source  retweet_count  like_count  \\\n5394              471.0         False     NaN            0.0         0.0   \n21694            4194.0         False     NaN          155.0         0.0   \n8580             2611.0         False     NaN            2.0         0.0   \n5074           337116.0         False     NaN          391.0         0.0   \n23988           31147.0         False     NaN            0.0         0.0   \n13258           44085.0         False     NaN          351.0         0.0   \n22030           33378.0         False     NaN         1541.0         0.0   \n9216                9.0         False     NaN            0.0         0.0   \n17567           45669.0          True     NaN           43.0         0.0   \n9568             1175.0         False     NaN         3044.0         0.0   \n\n       reply_count  impression_count  \n5394           0.0              16.0  \n21694          0.0               0.0  \n8580           0.0               0.0  \n5074           0.0               0.0  \n23988          0.0              15.0  \n13258          0.0               0.0  \n22030          0.0               0.0  \n9216           1.0              11.0  \n17567          0.0               0.0  \n9568           0.0               0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>tweet_created</th>\n      <th>tweet_extracted</th>\n      <th>text</th>\n      <th>lang</th>\n      <th>user_id</th>\n      <th>user_name</th>\n      <th>user_username</th>\n      <th>user_location</th>\n      <th>user_description</th>\n      <th>user_created</th>\n      <th>user_followers_count</th>\n      <th>user_following_count</th>\n      <th>user_tweet_count</th>\n      <th>user_verified</th>\n      <th>source</th>\n      <th>retweet_count</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>impression_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5394</th>\n      <td>1.6441126481229005e+18</td>\n      <td>2023-04-06 22:59:36+00:00</td>\n      <td>2023-04-08 02:25:52.995103</td>\n      <td>.@Expedia is integrating #ChatGPT into its app...</td>\n      <td>en</td>\n      <td>1580579004460851200</td>\n      <td>Kelsi Lee</td>\n      <td>LeeKelslee</td>\n      <td>NaN</td>\n      <td>Tech Recruiter at Expedia Group!! Dreams about...</td>\n      <td>2022-10-13 15:19:43+00:00</td>\n      <td>18.0</td>\n      <td>376.0</td>\n      <td>471.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>21694</th>\n      <td>1649337047679930371</td>\n      <td>2023-04-21 08:59:30+00:00</td>\n      <td>2023-04-23 21:54:55.928600</td>\n      <td>RT @itolife: 完全勝利しました！！（素振り）\\n本日22時から……ChatGPT...</td>\n      <td>ja</td>\n      <td>33908473</td>\n      <td>Francesc Puigdemont Sanz</td>\n      <td>francescsanz</td>\n      <td>Barcelona</td>\n      <td>InternetEntrepreneur, Growth&amp;Marketing lover, ...</td>\n      <td>2009-04-21 13:50:19+00:00</td>\n      <td>890.0</td>\n      <td>933.0</td>\n      <td>4194.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>155.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8580</th>\n      <td>1.6447165609412076e+18</td>\n      <td>2023-04-08 14:59:20+00:00</td>\n      <td>2023-04-10 23:11:22.510407</td>\n      <td>RT @ThugStyle4ever: GPT-4無料で使えるやん\\nBingに実装されとる...</td>\n      <td>ja</td>\n      <td>2281944000</td>\n      <td>京都室町さろん・Kyoto Muromachi Salon・</td>\n      <td>muromachisalon</td>\n      <td>NaN</td>\n      <td>💁🏻‍♀️心豊かに自己表現の自由な空間・Art de vivre・ 🏡 京町家 生谷家住宅 ...</td>\n      <td>2014-01-08 10:27:57+00:00</td>\n      <td>38.0</td>\n      <td>191.0</td>\n      <td>2611.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5074</th>\n      <td>1.6440824590957322e+18</td>\n      <td>2023-04-06 20:59:38+00:00</td>\n      <td>2023-04-08 02:25:50.670032</td>\n      <td>RT @stupefy_Malfoy: ใช่ๆ นี่เคยหาเปเป้อที่เป็น...</td>\n      <td>th</td>\n      <td>2357295380</td>\n      <td>🌹</td>\n      <td>TiaraMagica</td>\n      <td>Gotham City</td>\n      <td>🐉 she/her 🧚‍♀️ intersectional feminist &amp; multi...</td>\n      <td>2014-02-23 02:33:24+00:00</td>\n      <td>422.0</td>\n      <td>1228.0</td>\n      <td>337116.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>391.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>23988</th>\n      <td>1649971278475063296</td>\n      <td>2023-04-23 02:59:42+00:00</td>\n      <td>2023-04-25 21:30:42.316316</td>\n      <td>このつぶやきが意味不明な人にはChatGPTは向いてない。\\nけれども結果的にはいつの間にか...</td>\n      <td>ja</td>\n      <td>108174833</td>\n      <td>牧野尚人makino takahito</td>\n      <td>tkmakino</td>\n      <td>Sapporo,Hokkaido,Japan</td>\n      <td>H2×O2水素発電車FCEV＝TOYOTA MIRAI2016年式で3度目の越冬&amp;Schoo...</td>\n      <td>2010-01-25 02:59:59+00:00</td>\n      <td>255.0</td>\n      <td>190.0</td>\n      <td>31147.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>13258</th>\n      <td>1.6463323282293391e+18</td>\n      <td>2023-04-13 01:59:49+00:00</td>\n      <td>2023-04-15 22:21:44.924258</td>\n      <td>RT @gigazine: ゲームのNPCにChatGPTを仕込んだら勝手にパーティーの計画...</td>\n      <td>ja</td>\n      <td>269778793</td>\n      <td>中谷キョウ</td>\n      <td>nakayakyo</td>\n      <td>ちーば君の口の上あたり</td>\n      <td>小説とか書きます。 マンガ、アニメ、ラノベに強い。</td>\n      <td>2011-03-21 12:45:57+00:00</td>\n      <td>1500.0</td>\n      <td>1534.0</td>\n      <td>44085.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>351.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>22030</th>\n      <td>1649835413996019712</td>\n      <td>2023-04-22 17:59:49+00:00</td>\n      <td>2023-04-24 21:35:01.277494</td>\n      <td>RT @DefenderEurop: 🔵 \"Cette jeune fille est ch...</td>\n      <td>fr</td>\n      <td>1276859037905309698</td>\n      <td>Philippe Lagaune</td>\n      <td>PLagaune</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-06-27 12:45:23+00:00</td>\n      <td>1321.0</td>\n      <td>3331.0</td>\n      <td>33378.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1541.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9216</th>\n      <td>1.6449432076111094e+18</td>\n      <td>2023-04-09 05:59:56+00:00</td>\n      <td>2023-04-11 22:54:23.343471</td>\n      <td>ChatGPT recommended online casino JILIACE for ...</td>\n      <td>en</td>\n      <td>1623547784703139842</td>\n      <td>JILIACE</td>\n      <td>jiliace88</td>\n      <td>philippines</td>\n      <td>online casino philippines with free signup bonus</td>\n      <td>2023-02-09 05:02:23+00:00</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>9.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>17567</th>\n      <td>1647917682933764097</td>\n      <td>2023-04-17 10:59:27+00:00</td>\n      <td>2023-04-19 21:59:48.128929</td>\n      <td>RT @xo749100naniha: 一億総無思考社会へ。平気でウソをつくChatGPTを...</td>\n      <td>ja</td>\n      <td>486573105</td>\n      <td>inKstall Educare</td>\n      <td>Inkstall</td>\n      <td>Global</td>\n      <td>Installing knowledge since 12 years.\\nLearning...</td>\n      <td>2012-02-08 12:47:39+00:00</td>\n      <td>212.0</td>\n      <td>4.0</td>\n      <td>45669.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>43.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9568</th>\n      <td>1.645124213617967e+18</td>\n      <td>2023-04-09 17:59:12+00:00</td>\n      <td>2023-04-11 22:54:37.481343</td>\n      <td>RT @FrKadel: My daughter, who's had a degree i...</td>\n      <td>en</td>\n      <td>886774963855736832</td>\n      <td>陈桐晓</td>\n      <td>chentongxiao</td>\n      <td>United States</td>\n      <td>one</td>\n      <td>2017-07-17 02:30:01+00:00</td>\n      <td>23.0</td>\n      <td>447.0</td>\n      <td>1175.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3044.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:18:31.290785700Z",
     "start_time": "2023-05-24T12:18:31.266214100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 2: Exploratory Data Analysis and Preprocessing¶"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                 tweet_id                                               text  \\\n0   1.642889622681432e+18  RT @jexep: เทคนิคฝึกภาษากับ ChatGPT ที่ผมลอง (...   \n1  1.6428442314496123e+18  ChatGPTをもっと活かせるChrome拡張機能4選 https://t.co/hfacF...   \n2  1.6427385624866693e+18  RT @DarrellLerner: ChatGPT Plugins are the fas...   \n3  1.6429198880616448e+18  Get an intelligent chatbot for your website in...   \n4   1.642708351690711e+18  🔥Hey Guys, #ZenithSwap has launched at just $ ...   \n\n     user_location lang  \n0  ในใจJacksonwang   th  \n1            東京←岐阜   ja  \n2            India   en  \n3   United Kingdom   en  \n4      Chicago, IL   en  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n      <th>user_location</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.642889622681432e+18</td>\n      <td>RT @jexep: เทคนิคฝึกภาษากับ ChatGPT ที่ผมลอง (...</td>\n      <td>ในใจJacksonwang</td>\n      <td>th</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.6428442314496123e+18</td>\n      <td>ChatGPTをもっと活かせるChrome拡張機能4選 https://t.co/hfacF...</td>\n      <td>東京←岐阜</td>\n      <td>ja</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.6427385624866693e+18</td>\n      <td>RT @DarrellLerner: ChatGPT Plugins are the fas...</td>\n      <td>India</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.6429198880616448e+18</td>\n      <td>Get an intelligent chatbot for your website in...</td>\n      <td>United Kingdom</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.642708351690711e+18</td>\n      <td>🔥Hey Guys, #ZenithSwap has launched at just $ ...</td>\n      <td>Chicago, IL</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the columns you want\n",
    "df = df[['tweet_id', 'text', 'user_location', 'lang']]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:18:53.190351700Z",
     "start_time": "2023-05-24T12:18:53.145490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(25002, 4)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:18:58.715904Z",
     "start_time": "2023-05-24T12:18:58.694904800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "10236"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_location'].isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:04.108664300Z",
     "start_time": "2023-05-24T12:19:04.093665100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the 'user_location' column\n",
    "df = df.dropna(subset=['user_location'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:09.167818600Z",
     "start_time": "2023-05-24T12:19:09.150800100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(14766, 4)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:13.749424300Z",
     "start_time": "2023-05-24T12:19:13.743424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "en         6707\nja         3834\nes         1422\nfr          559\nzh          472\npt          358\ntr          192\nar          178\nth          168\nde          130\nko          124\nit           77\nin           73\nund          67\nqme          54\nzxx          45\nca           34\npl           32\nfa           32\nru           31\nnl           28\ncs           18\ncy           16\ntl           14\nuk           11\nfi            9\niw            9\nsv            8\nhi            8\nda            6\nhu            5\nel            5\net            5\nlv            4\nur            4\nht            4\nqht           4\nvi            3\nsl            3\nta            3\ngu            2\nsr            1\nno            1\nml            1\n147.0         1\nro            1\n14918.0       1\nckb           1\nmr            1\nName: lang, dtype: int64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lang'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:18.319661900Z",
     "start_time": "2023-05-24T12:19:18.274292200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Filter rows based on language\n",
    "languages_to_keep = ['en', 'es', 'fr']\n",
    "df = df[df['lang'].isin(languages_to_keep)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:27.834145400Z",
     "start_time": "2023-05-24T12:19:27.818145Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(8688, 4)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:32.423566900Z",
     "start_time": "2023-05-24T12:19:32.395070300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                     tweet_id  \\\n7671    1.644218267274281e+18   \n14824     1646785257440530435   \n18823     1648400969275785218   \n15680     1647238226208489473   \n13151  1.6465588429336084e+18   \n15803     1647102298487652352   \n5119   1.6440220885108736e+18   \n21987     1649472829476184068   \n14973     1646996577934778368   \n24368     1650590195627032578   \n\n                                                    text  \\\n7671   RT @business_libre_: Les gens gagnent des mill...   \n14824  RT @rowancheung: Thought ChatGPT was crazy? Ev...   \n18823  RT @infomoneypro: ChatGPT n'est qu'une goutte ...   \n15680  https://t.co/WB9go0nf2y - Musk Reportedly Crea...   \n13151  RT @Chain_GPT_web: 📢ChainGPT #Airdrop incoming...   \n15803  Hoy le pedí a chatgpt que escribiera nuestra h...   \n5119   RT @JonathanTurley: ...I learned that ChatGPT ...   \n21987  No one wants your stupid “homework sub” ass wh...   \n14973  RT @Tony_Lantes: Impresionantes prompt de chat...   \n24368  RT @NihalKrishan: NEWS: ChatGPT has arrived in...   \n\n                        user_location lang  \n7671                           suisse   fr  \n14824                              sg   en  \n18823                   Paris, France   fr  \n15680  Misty Mountains, Middle Earth    en  \n13151                    Brooklyn, NY   en  \n15803                 Puerto Vallarta   es  \n5119                   Fort Myers, FL   en  \n21987                 12.087€/13.000€   en  \n14973                              日本   fr  \n24368                       El exito🔝   en  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n      <th>user_location</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7671</th>\n      <td>1.644218267274281e+18</td>\n      <td>RT @business_libre_: Les gens gagnent des mill...</td>\n      <td>suisse</td>\n      <td>fr</td>\n    </tr>\n    <tr>\n      <th>14824</th>\n      <td>1646785257440530435</td>\n      <td>RT @rowancheung: Thought ChatGPT was crazy? Ev...</td>\n      <td>sg</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>18823</th>\n      <td>1648400969275785218</td>\n      <td>RT @infomoneypro: ChatGPT n'est qu'une goutte ...</td>\n      <td>Paris, France</td>\n      <td>fr</td>\n    </tr>\n    <tr>\n      <th>15680</th>\n      <td>1647238226208489473</td>\n      <td>https://t.co/WB9go0nf2y - Musk Reportedly Crea...</td>\n      <td>Misty Mountains, Middle Earth</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>13151</th>\n      <td>1.6465588429336084e+18</td>\n      <td>RT @Chain_GPT_web: 📢ChainGPT #Airdrop incoming...</td>\n      <td>Brooklyn, NY</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>15803</th>\n      <td>1647102298487652352</td>\n      <td>Hoy le pedí a chatgpt que escribiera nuestra h...</td>\n      <td>Puerto Vallarta</td>\n      <td>es</td>\n    </tr>\n    <tr>\n      <th>5119</th>\n      <td>1.6440220885108736e+18</td>\n      <td>RT @JonathanTurley: ...I learned that ChatGPT ...</td>\n      <td>Fort Myers, FL</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>21987</th>\n      <td>1649472829476184068</td>\n      <td>No one wants your stupid “homework sub” ass wh...</td>\n      <td>12.087€/13.000€</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>14973</th>\n      <td>1646996577934778368</td>\n      <td>RT @Tony_Lantes: Impresionantes prompt de chat...</td>\n      <td>日本</td>\n      <td>fr</td>\n    </tr>\n    <tr>\n      <th>24368</th>\n      <td>1650590195627032578</td>\n      <td>RT @NihalKrishan: NEWS: ChatGPT has arrived in...</td>\n      <td>El exito🔝</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:36.785020600Z",
     "start_time": "2023-05-24T12:19:36.738546500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "df = df[['tweet_id', 'text', 'lang']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:45.187647400Z",
     "start_time": "2023-05-24T12:19:45.157716200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "possible_labels = df.lang.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:49.718593700Z",
     "start_time": "2023-05-24T12:19:49.713595700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:54.357983200Z",
     "start_time": "2023-05-24T12:19:54.352982600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "df['label'] = df.lang.replace(label_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:19:58.682167600Z",
     "start_time": "2023-05-24T12:19:58.659154200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "                     tweet_id  \\\n12235  1.6460604778086154e+18   \n19122     1648823696444850176   \n22247     1649775020233699328   \n9027   1.6451998266474127e+18   \n15312     1647147575366107136   \n7999    1.644187971372089e+18   \n6370   1.6439011532880443e+18   \n13726  1.6465588488685486e+18   \n16909     1647570197958520832   \n13184   1.646422771319341e+18   \n\n                                                    text lang  label  \n12235  @French_Jim @unusual_whales Do you have a sour...   en      0  \n19122  En Redmond están que lo tiran con el segmento ...   es      2  \n22247  RT @GuiSimonin: Le ChatGPT de la finance est l...   fr      1  \n9027   RT @TheRundownAI: This is going to make ChatGP...   en      0  \n15312  RT @ebubensukka_esq: Yo!!!! I got so confused ...   en      0  \n7999   RT @Time_and_Trade: This is what Chatgpt told ...   en      0  \n6370   RT @nudpiedo: “Samsung meeting notes and new s...   en      0  \n13726  RT @Chain_GPT_web: 📢ChainGPT #Airdrop incoming...   en      0  \n16909  RT @platzi: ¿Sientes que eres la única persona...   es      2  \n13184  RT @MushtaqBilalPhD: How to build an academic ...   en      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n      <th>lang</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12235</th>\n      <td>1.6460604778086154e+18</td>\n      <td>@French_Jim @unusual_whales Do you have a sour...</td>\n      <td>en</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19122</th>\n      <td>1648823696444850176</td>\n      <td>En Redmond están que lo tiran con el segmento ...</td>\n      <td>es</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>22247</th>\n      <td>1649775020233699328</td>\n      <td>RT @GuiSimonin: Le ChatGPT de la finance est l...</td>\n      <td>fr</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9027</th>\n      <td>1.6451998266474127e+18</td>\n      <td>RT @TheRundownAI: This is going to make ChatGP...</td>\n      <td>en</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15312</th>\n      <td>1647147575366107136</td>\n      <td>RT @ebubensukka_esq: Yo!!!! I got so confused ...</td>\n      <td>en</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7999</th>\n      <td>1.644187971372089e+18</td>\n      <td>RT @Time_and_Trade: This is what Chatgpt told ...</td>\n      <td>en</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6370</th>\n      <td>1.6439011532880443e+18</td>\n      <td>RT @nudpiedo: “Samsung meeting notes and new s...</td>\n      <td>en</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13726</th>\n      <td>1.6465588488685486e+18</td>\n      <td>RT @Chain_GPT_web: 📢ChainGPT #Airdrop incoming...</td>\n      <td>en</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16909</th>\n      <td>1647570197958520832</td>\n      <td>RT @platzi: ¿Sientes que eres la única persona...</td>\n      <td>es</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13184</th>\n      <td>1.646422771319341e+18</td>\n      <td>RT @MushtaqBilalPhD: How to build an academic ...</td>\n      <td>en</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:20:02.850111Z",
     "start_time": "2023-05-24T12:20:02.822112600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 3: Training/Validation Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:20:21.184553100Z",
     "start_time": "2023-05-24T12:20:21.145788Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
    "                                                  df.label.values,\n",
    "                                                  test_size=0.15,\n",
    "                                                  random_state=17,\n",
    "                                                  stratify=df.label.values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:20:35.853365800Z",
     "start_time": "2023-05-24T12:20:35.847336Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:20:40.376064400Z",
     "start_time": "2023-05-24T12:20:40.360064200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "                      tweet_id  text\nlang label data_type                \nen   0     train          5700  5700\n           val            1007  1007\nes   2     train          1209  1209\n           val             213   213\nfr   1     train           475   475\n           val              84    84",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>lang</th>\n      <th>label</th>\n      <th>data_type</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">en</th>\n      <th rowspan=\"2\" valign=\"top\">0</th>\n      <th>train</th>\n      <td>5700</td>\n      <td>5700</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>1007</td>\n      <td>1007</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">es</th>\n      <th rowspan=\"2\" valign=\"top\">2</th>\n      <th>train</th>\n      <td>1209</td>\n      <td>1209</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>213</td>\n      <td>213</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">fr</th>\n      <th rowspan=\"2\" valign=\"top\">1</th>\n      <th>train</th>\n      <td>475</td>\n      <td>475</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>84</td>\n      <td>84</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['lang', 'label', 'data_type']).count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:20:44.602107Z",
     "start_time": "2023-05-24T12:20:44.563913100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 4: Loading Tokenizer and Encoding our Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:21:17.760971200Z",
     "start_time": "2023-05-24T12:21:17.737275200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99427bff22d8432d9ebe90185a986366"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\maxim\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94db6056fedf4dd580787147359e2acc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06ffd0e7d809443f84432ee1dd54a311"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
    "                                          do_lower_case=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:21:26.414374700Z",
     "start_time": "2023-05-24T12:21:24.547782700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "D:\\Anaconda\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:21:43.924540200Z",
     "start_time": "2023-05-24T12:21:38.336539900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:21:48.144609400Z",
     "start_time": "2023-05-24T12:21:48.117002Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "7384"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:21:53.114405800Z",
     "start_time": "2023-05-24T12:21:53.080939800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "1304"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:21:57.658150900Z",
     "start_time": "2023-05-24T12:21:57.644107300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 5: Setting up BERT Pretrained Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:22:35.344644500Z",
     "start_time": "2023-05-24T12:22:35.292644200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92e86f99e4ca4ec2b6dbbf7ac1c1d9f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:23:34.287182100Z",
     "start_time": "2023-05-24T12:22:51.225403100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T12:23:34.302800300Z",
     "start_time": "2023-05-24T12:23:34.287182100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.lower()\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "df = df[df['lang'] == 'en']"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
